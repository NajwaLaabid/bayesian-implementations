{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP in JAX\n",
    "\n",
    "This is an exploration of the basic concepts of JAX by building a Multi-Layer Perceptron. This notebook follows Robert Lange's [tutorial](https://roberttlange.github.io/posts/2020/03/blog-post-10/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elaanaj/miniconda3/lib/python3.7/site-packages/jax/lib/xla_bridge.py:116: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "\n",
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98.3 ms, sys: 57.4 ms, total: 156 ms\n",
      "Wall time: 27.7 ms\n",
      "CPU times: user 15.3 ms, sys: 34.7 ms, total: 49.9 ms\n",
      "Wall time: 7.36 ms\n",
      "CPU times: user 190 ms, sys: 187 ms, total: 377 ms\n",
      "Wall time: 54.9 ms\n"
     ]
    }
   ],
   "source": [
    "# Generate a random matrix\n",
    "x = random.uniform(key, (1000, 1000))\n",
    "# Compare running times of 3 different matrix multiplications\n",
    "%time y = onp.dot(x, x)\n",
    "%time y = np.dot(x, x)\n",
    "%time y = np.dot(x, x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Basic Concepts & Conventions - jit, grad & vmap\n",
    "\n",
    "Before diving into the nitty-gritty details of training some neural nets in JAX, let's have a look at the basic ingredients that make things work. **jit** (just-in-time compilation) lies at the core of speeding up your code. In practice we simply wrap (`jit()`) or decorate (`@jit`) the function of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    \"\"\" Rectified Linear Unit (ReLU) activation function \"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "jit_ReLU = jit(ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time we call the jitted function it will be compiled and it may take a little longer. But afterwards, the machine code is ready to shine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 ms, sys: 0 ns, total: 40.5 ms\n",
      "Wall time: 38.7 ms\n",
      "CPU times: user 18.4 ms, sys: 0 ns, total: 18.4 ms\n",
      "Wall time: 16.9 ms\n",
      "CPU times: user 1.87 ms, sys: 0 ns, total: 1.87 ms\n",
      "Wall time: 605 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time out = ReLU(x).block_until_ready()\n",
    "# Call jitted version to compile for evaluation time!\n",
    "%time jit_ReLU(x).block_until_ready()\n",
    "%time out = jit_ReLU(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next tool in our kit is **grad**. It is the autodiff backbone of JAX and is inherited from the Autograd package. By wrapping your function with grad and evaluating it, you get the gradient evaluation returned. Let's have a look at how this would work with our ReLU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax Grad:  1.0\n",
      "FD Gradient: 0.99998707\n"
     ]
    }
   ],
   "source": [
    "def FiniteDiffGrad(x):\n",
    "    \"\"\" Compute the finite difference derivative approx for the ReLU\"\"\"\n",
    "    return np.array((ReLU(x + 1e-3) - ReLU(x - 1e-3)) / (2 * 1e-3))\n",
    "\n",
    "# Compare the Jax gradient with a finite difference approximation\n",
    "print(\"Jax Grad: \", jit(grad(jit(ReLU)))(2.))\n",
    "print(\"FD Gradient:\", FiniteDiffGrad(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dim = 32\n",
    "feature_dim = 100\n",
    "hidden_dim = 512\n",
    "\n",
    "# Generate a batch of vectors to process\n",
    "X = random.normal(key, (batch_dim, feature_dim))\n",
    "\n",
    "# Generate Gaussian weights and biases\n",
    "params = [random.normal(key, (hidden_dim, feature_dim)),\n",
    "          random.normal(key, (hidden_dim, ))] \n",
    "\n",
    "def relu_layer(params, x):\n",
    "    \"\"\" Simple ReLu layer for single sample \"\"\"\n",
    "    return ReLU(np.dot(params[0], x) + params[1])\n",
    "\n",
    "def batch_version_relu_layer(params, x):\n",
    "    \"\"\" Error prone batch version \"\"\"\n",
    "    return ReLU(np.dot(X, params[0].T) + params[1])\n",
    "\n",
    "def vmap_relu_layer(params, x):\n",
    "    \"\"\" vmap version of the ReLU layer \"\"\"\n",
    "    return jit(vmap(relu_layer, in_axes=(None, 0), out_axes=0))\n",
    "\n",
    "out = np.stack([relu_layer(params, X[i, :]) for i in range(X.shape[0])])\n",
    "out = batch_version_relu_layer(params, X)\n",
    "out = vmap_relu_layer(params, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a MNIST Multilayer Perceptron in JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/elaanaj/miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    torchvision-0.8.2          |       py37_cu110        18.0 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        18.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.11-h396b838_0\n",
      "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
      "  pillow             pkgs/main/linux-64::pillow-8.1.0-py37he98fc37_0\n",
      "  torchvision        pytorch/linux-64::torchvision-0.8.2-py37_cu110\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  freetype                                2.10.2-h5ab3b9f_0 --> 2.10.4-h5ab3b9f_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchvision-0.8.2    | 18.0 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c pytorch torchvision -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some additional JAX and dataloader helpers\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "from utils import jax_utils as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209835da9ae445349b39f2cf307c36a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a152d4e2444011b53f781459b09a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf7fad036c48239e7734913af87ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43de7a159d48453b86828a882097b3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elaanaj/miniconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 190,
       "width": 682
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the PyTorch Data Loader for the training & test set\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "helpers.plot_mnist_examples(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_mlp(sizes, key):\n",
    "    \"\"\" Initialize the weights of all layers of a linear layer network \"\"\"\n",
    "    keys = random.split(key, len(sizes))\n",
    "    # Initialize a single layer with Gaussian weights -  helper function\n",
    "    def initialize_layer(m, n, key, scale=1e-2):\n",
    "        w_key, b_key = random.split(key)\n",
    "        return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "    return [initialize_layer(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "layer_sizes = [784, 512, 512, 10]\n",
    "# Return a list of tuples of layer weights\n",
    "params = initialize_mlp(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(params, in_array):\n",
    "    \"\"\" Compute the forward pass for each example individually \"\"\"\n",
    "    activations = in_array\n",
    "    \n",
    "    # Loop over the ReLU hidden layers\n",
    "    for w, b in params[:-1]:\n",
    "        activations = relu_layer([w, b], activations)\n",
    "    \n",
    "    # Perform final trafo to logits\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = np.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)\n",
    "\n",
    "# Make a batched version of the `predict` function\n",
    "batch_forward = vmap(forward_pass, in_axes=(None, 0), out_axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k \"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "def loss(params, in_arrays, targets):\n",
    "    \"\"\" Compute the multi-class cross-entropy loss \"\"\"\n",
    "    preds = batch_forward(params, in_arrays)\n",
    "    return -np.sum(preds * targets)\n",
    "  \n",
    "def accuracy(params, data_loader):\n",
    "    \"\"\" Compute the accuracy for a provided dataloader \"\"\"\n",
    "    acc_total = 0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        images = np.array(data).reshape(data.size(0), 28*28)\n",
    "        targets = one_hot(np.array(target), num_classes)\n",
    "    \n",
    "        target_class = np.argmax(targets, axis=1)\n",
    "        predicted_class = np.argmax(batch_forward(params, images), axis=1)\n",
    "        acc_total += np.sum(predicted_class == target_class)\n",
    "    return acc_total/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value\n",
    "\n",
    "# Defining an optimizer in Jax\n",
    "step_size = 1e-3\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "num_epochs = 10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | T: 10.73 | Train A: 0.975 | Test A: 0.970\n",
      "Epoch 2 | T: 10.67 | Train A: 0.984 | Test A: 0.977\n",
      "Epoch 3 | T: 10.74 | Train A: 0.990 | Test A: 0.977\n",
      "Epoch 4 | T: 10.85 | Train A: 0.991 | Test A: 0.978\n",
      "Epoch 5 | T: 10.89 | Train A: 0.995 | Test A: 0.980\n",
      "Epoch 6 | T: 10.78 | Train A: 0.995 | Test A: 0.980\n",
      "Epoch 7 | T: 10.69 | Train A: 0.997 | Test A: 0.979\n",
      "Epoch 8 | T: 10.78 | Train A: 0.998 | Test A: 0.983\n",
      "Epoch 9 | T: 10.75 | Train A: 0.999 | Test A: 0.983\n"
     ]
    }
   ],
   "source": [
    "def run_mnist_training_loop(num_epochs, opt_state, net_type=\"MLP\"):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Initialize placeholder for loggin\n",
    "    log_acc_train, log_acc_test, train_loss = [], [], []\n",
    "    \n",
    "    # Get the initial set of parameters \n",
    "    params = get_params(opt_state)\n",
    "    \n",
    "    # Get initial accuracy after random init\n",
    "    train_acc = accuracy(params, train_loader)\n",
    "    test_acc = accuracy(params, test_loader)\n",
    "    log_acc_train.append(train_acc)\n",
    "    log_acc_test.append(test_acc)\n",
    "    \n",
    "    # Loop over the training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if net_type == \"MLP\":\n",
    "                # Flatten the image into 784 vectors for the MLP\n",
    "                x = np.array(data).reshape(data.size(0), 28*28)\n",
    "            elif net_type == \"CNN\":\n",
    "                # No flattening of the input required for the CNN\n",
    "                x = np.array(data)\n",
    "            y = one_hot(np.array(target), num_classes)\n",
    "            params, opt_state, loss = update(params, x, y, opt_state)\n",
    "            train_loss.append(loss)\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_acc = accuracy(params, train_loader)\n",
    "        test_acc = accuracy(params, test_loader)\n",
    "        log_acc_train.append(train_acc)\n",
    "        log_acc_test.append(test_acc)\n",
    "        print(\"Epoch {} | T: {:0.2f} | Train A: {:0.3f} | Test A: {:0.3f}\".format(epoch+1, epoch_time,\n",
    "                                                                    train_acc, test_acc))\n",
    "    \n",
    "    return train_loss, log_acc_train, log_acc_test\n",
    "\n",
    "\n",
    "train_loss, train_log, test_log = run_mnist_training_loop(num_epochs,\n",
    "                                                          opt_state,\n",
    "                                                          net_type=\"MLP\")\n",
    "\n",
    "# Plot the loss curve over time\n",
    "helpers.plot_mnist_performance(train_loss, train_log, test_log,\n",
    "                       \"MNIST MLP Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
